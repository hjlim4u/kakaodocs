import pytest
import pandas as pd
from datetime import datetime
import networkx as nx
from src.utils.interaction_analyzer import InteractionAnalyzer
from src.utils.text_processor import TextProcessor
import asyncio
import psutil
import os

@pytest.fixture
def sample_df():
    data = {
        'datetime': [
            datetime(2024, 1, 1, 12, 0),
            datetime(2024, 1, 1, 12, 1),
            datetime(2024, 1, 1, 12, 2)
        ],
        'sender': ['User1', 'User2', 'User1'],
        'message': ['ì•ˆë…•í•˜ì„¸ìš”', 'ë°˜ê°‘ìŠµë‹ˆë‹¤', 'ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”']
    }
    return pd.DataFrame(data)

@pytest.fixture
def analyzer():
    text_processor = TextProcessor()
    return InteractionAnalyzer(text_processor)

def test_preprocess_message(analyzer):
    message = "ì•ˆë…•í•˜ì„¸ìš” ã…‹ã…‹ã…‹ ğŸ˜Š http://example.com"
    result = analyzer._preprocess_message(message)
    assert '[LAUGH]' in result
    assert '[EMOJI]' in result
    assert 'http://example.com' not in result

@pytest.mark.asyncio
async def test_analyze_interactions(analyzer, sample_df):
    # í…ŒìŠ¤íŠ¸ìš© thread_results ìƒì„±
    thread_results = {
        'threads': [
            [sample_df['datetime'].min(), sample_df['datetime'].max()]
        ],
        'thread_stats': {
            'total_threads': 1,
            'avg_thread_length': 120,
            'max_thread_length': 120
        }
    }
    
    # chat_id ì¶”ê°€
    chat_id = 'test_chat'
    
    result = await analyzer.analyze_interactions(sample_df, chat_id, thread_results)
    
    # ê¸°ë³¸ ê²€ì¦
    assert isinstance(result['network'], nx.Graph)
    assert 'centrality' in result
    assert 'density' in result
    assert 'thread_stats' in result
    assert 'language_style_analysis' in result
    
    # ì–¸ì–´ ìŠ¤íƒ€ì¼ ë¶„ì„ ê²°ê³¼ ê²€ì¦
    style_analysis = result['language_style_analysis']
    assert 'user_styles' in style_analysis
    assert 'style_similarities' in style_analysis

def test_extract_style_features(analyzer):
    messages = pd.Series(['ì•ˆë…•í•˜ì„¸ìš”!', 'ì˜ ì§€ë‚´ì‹œë‚˜ìš”? ã…ã…'])
    result = analyzer._extract_style_features(messages)
    assert 'lexical_features' in result
    assert 'morphological_features' in result
    assert 'syntactic_features' in result

def test_analyze_language_style(analyzer, sample_df):
    chat_id = 'test_chat'
    result = analyzer._analyze_language_style(sample_df, chat_id)
    
    assert isinstance(result, dict)
    assert 'user_styles' in result
    assert 'style_similarities' in result 

@pytest.mark.asyncio
async def test_analyze_interactions_with_invalid_input(analyzer):
    """ì˜ëª»ëœ ì…ë ¥ì— ëŒ€í•œ ì˜ˆì™¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    with pytest.raises(ValueError):
        await analyzer.analyze_interactions(
            pd.DataFrame(),  # ë¹ˆ ë°ì´í„°í”„ë ˆì„
            'test_chat'
        )

@pytest.mark.asyncio
async def test_analyze_interactions_with_single_user(analyzer, sample_df):
    """ë‹¨ì¼ ì‚¬ìš©ì ëŒ€í™” ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    single_user_df = sample_df.copy()
    single_user_df['sender'] = 'User1'
    result = await analyzer.analyze_interactions(single_user_df, 'test_chat')
    
    assert result['language_style_analysis']['style_similarities'] == {}
    assert result['network'].number_of_nodes() == 1
    assert result['density'] == 0

@pytest.mark.asyncio
async def test_style_feature_extraction_with_empty_messages(analyzer):
    """ë¹ˆ ë©”ì‹œì§€ì— ëŒ€í•œ ìŠ¤íƒ€ì¼ íŠ¹ì„± ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    empty_messages = pd.Series(['', ' ', '  '])
    result = analyzer._extract_style_features(empty_messages)
    
    assert result['lexical_features']['avg_length'] == 0
    assert result['morphological_features']['pos_ratios'] == {}
    assert result['syntactic_features']['question_rate'] == 0 

@pytest.mark.asyncio
async def test_concurrent_interaction_analysis(analyzer):
    """ë™ì‹œ ë¶„ì„ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    chat_ids = [f'test_chat_{i}' for i in range(3)]
    dfs = [sample_df.copy() for _ in range(3)]
    
    tasks = [
        analyzer.analyze_interactions(df, chat_id)
        for df, chat_id in zip(dfs, chat_ids)
    ]
    results = await asyncio.gather(*tasks)
    
    assert len(results) == 3
    assert all('language_style_analysis' in r for r in results)

@pytest.mark.asyncio
async def test_memory_usage(analyzer, sample_df):
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
    process = psutil.Process(os.getpid())
    initial_memory = process.memory_info().rss
    
    # ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    large_df = pd.concat([sample_df] * 1000, ignore_index=True)
    await analyzer.analyze_interactions(large_df, 'test_chat')
    
    final_memory = process.memory_info().rss
    memory_increase = (final_memory - initial_memory) / 1024 / 1024  # MB
    assert memory_increase < 500  # ë©”ëª¨ë¦¬ ì¦ê°€ê°€ 500MB ì´í•˜ 